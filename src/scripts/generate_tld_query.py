import requests
import json
import sys
import time
from collections import Counter
from typing import List
from datetime import datetime

def fetch_and_generate_queries(tld_count=50):
    try:
        # Common legitimate TLDs to exclude
        blacklisted_tlds = {
            'com', 'net', 'org', 'nl'
        }
        
        url = "https://isc.sans.edu/api/recentdomains?json"
        print(f"[INFO] Making request to: {url}")
        
        print("[INFO] Waiting 15 seconds before making request...")
        time.sleep(15)
        
        max_retries = 3
        retry_count = 0
        
        headers = {
            'User-Agent': 'StormInt',
            'Accept': 'application/json',
            'Accept-Language': 'en-US,en;q=0.9'
        }
        
        while retry_count < max_retries:
            start_time = time.time()
            response = requests.get(url, headers=headers)
            elapsed_time = time.time() - start_time
            
            print(f"[DEBUG] Status code: {response.status_code}")
            print(f"[DEBUG] Headers: {dict(response.headers)}")
            print(f"[DEBUG] Request duration: {elapsed_time:.2f} seconds")
            
            try:
                if elapsed_time < 10:
                    wait_time = 10 - elapsed_time
                    print(f"[INFO] Waiting extra {wait_time:.2f} seconds to avoid rate limiting...")
                    time.sleep(wait_time)
                
                data = response.json()
                if data:
                    print("[INFO] Successfully parsed JSON response.")
                    break
                else:
                    print("[WARN] Empty JSON response.")
            except json.JSONDecodeError:
                print(f"[ERROR] Failed to parse JSON (attempt {retry_count + 1}/{max_retries})")
                print(f"[DEBUG] Response preview: {response.text[:200]}...")
                print("[INFO] Retrying after 20 seconds...")
                time.sleep(20)
                retry_count += 1
                continue
        
        if retry_count == max_retries:
            print("[FATAL] Max retries reached. Exiting.")
            return
            
        # Extract and count TLDs, excluding blacklisted ones
        tlds = [
            domain["domainname"].rsplit(".", 1)[-1]
            for domain in data if domain.get("domainname") and "." in domain["domainname"]
            and domain["domainname"].rsplit(".", 1)[-1] not in blacklisted_tlds
        ]
        tld_counts = Counter(tlds)
        top_tlds = [tld for tld, _ in tld_counts.most_common(tld_count)]
        
        if not top_tlds:
            print("[ERROR] No valid TLDs extracted after blacklist filtering.")
            return

        print(f"[INFO] Top {len(top_tlds)} TLDs after blacklist filtering: {', '.join(top_tlds)}")
        
        # Generate and save queries
        url_query = generate_url_tld_query(top_tlds)
        sender_query = generate_sender_tld_query(top_tlds)
        
        # Save queries
        with open("generated/stormint_url_tld_query.kql", "w") as f:
            f.write(url_query)
            print("[INFO] URL TLD query saved to generated/stormint_url_tld_query.kql")
            
        with open("generated/stormint_sender_tld_query.kql", "w") as f:
            f.write(sender_query)
            print("[INFO] Sender TLD query saved to generated/stormint_sender_tld_query.kql")
            
    except requests.exceptions.RequestException as e:
        print(f"[ERROR] Request failed: {e}")
    except Exception as e:
        print(f"[ERROR] Unexpected error: {e}")

def generate_url_tld_query(tlds: List[str]) -> str:
    """Generate KQL query for URL TLDs."""
    # Convert TLDs to lowercase and remove duplicates
    tlds = list(set(tld.lower() for tld in tlds))
    
    # Create the KQL query
    query = f"""// Data sourced from SANS Internet Storm Center / DShield API (https://isc.sans.edu/api/)
// Generated by StormInt TLD Query Generator

let suspicious_tlds = dynamic({json.dumps(tlds)});
EmailUrlInfo
| where Url has_any (suspicious_tlds)
| project TimeGenerated, NetworkMessageId, Url
| join kind=inner (
    EmailEvents
    | project TimeGenerated, NetworkMessageId, Subject, SenderFromAddress, RecipientEmailAddress
) on NetworkMessageId
| project TimeGenerated, Subject, SenderFromAddress, RecipientEmailAddress, Url
| summarize count() by Subject, SenderFromAddress, RecipientEmailAddress, Url
| order by count_ desc
"""
    return query

def generate_sender_tld_query(tlds: List[str]) -> str:
    """Generate KQL query for sender TLDs."""
    # Convert TLDs to lowercase and remove duplicates
    tlds = list(set(tld.lower() for tld in tlds))
    
    # Create the KQL query
    query = f"""// Data sourced from SANS Internet Storm Center / DShield API (https://isc.sans.edu/api/)
// Generated by StormInt TLD Query Generator

let suspicious_tlds = dynamic({json.dumps(tlds)});
EmailEvents
| where SenderFromDomain has_any (suspicious_tlds)
| project TimeGenerated, Subject, SenderFromAddress, RecipientEmailAddress, SenderFromDomain
| summarize count() by Subject, SenderFromAddress, RecipientEmailAddress, SenderFromDomain
| order by count_ desc
"""
    return query

if __name__ == "__main__":
    tld_count = int(sys.argv[1]) if len(sys.argv) > 1 else 50
    fetch_and_generate_queries(tld_count)
